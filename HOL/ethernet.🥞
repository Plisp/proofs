/**
 * from util.pnk
 */

#define WORD_SIZE 8

#define microkit_notify(channel)        \
    @microkit_notify(0,channel,0,0);    \

#define microkit_irq_ack_delayed(channel)       \
    @microkit_irq_ack_delayed(0,channel,0,0);   \

#define THREAD_MEMORY_RELEASE()         \
    @THREAD_MEMORY_RELEASE(0,0,0,0);    \

// Returns a % b, asuming b = x^n for some x and n
#define pnk_modulo(result, a, b) \
    var result = a & (b - 1);    \

#define assert(assert_val)              \
    @assert(0,assert_val,0,0);          \

/**
 * from queue_helper.pnk
 */

#define NET_BUFF_DESC_SIZE (2 * WORD_SIZE)

#define get_size(size, queue_handle)                \
    var size = lds 1 queue_handle + 2 * WORD_SIZE;  \

#define get_tail(tail, queue)   \
    var tail = 0;               \
    !ldw tail, queue;           \

#define set_tail(tail, queue)   \
    !stw queue, tail;           \

#define get_head(head, queue)       \
    var head = 0;                   \
    !ldw head, queue + WORD_SIZE;   \

#define set_head(head, queue)       \
    !stw queue + WORD_SIZE, head;   \

#define get_consumer_signalled(signalled, queue)\
    var signalled = 0;                          \
    !ld8 signalled, queue + 2 * WORD_SIZE;      \

#define clear_consumer_signalled(queue) \
    var signal = 0;                     \
    !st8 queue + 2 * WORD_SIZE, signal; \

#define set_consumer_signalled(queue)   \
    var signal = 1;                     \
    st8 queue + 2 * WORD_SIZE, signal;  \

#define get_buffer_desc_addr(desc, index, queue)                    \
    var desc = queue + 3 * WORD_SIZE + index * NET_BUFF_DESC_SIZE;  \

#define get_free_queue(free, queue_handle)  \
    var free = lds 1 queue_handle;          \

#define get_active_queue(active, queue_handle)      \
    var active = lds 1 queue_handle + WORD_SIZE;    \

#define get_free_head(head, queue_handle)   \
    get_free_queue(queue, queue_handle)     \
    get_head(head, queue)

#define set_free_head(head, queue_handle)   \
    get_free_queue(queue, queue_handle)     \
    set_head(head, queue)

#define get_free_tail(tail, queue_handle)   \
    get_free_queue(queue, queue_handle)     \
    get_tail(tail, queue)

#define set_free_tail(tail, queue_handle)   \
    get_free_queue(queue, queue_handle)     \
    set_tail(tail, queue)

#define get_active_head(head, queue_handle) \
    get_active_queue(queue, queue_handle)   \
    get_head(head, queue)

#define set_active_head(head, queue_handle) \
    get_active_queue(queue, queue_handle)   \
    set_head(head, queue)

#define get_active_tail(tail, queue_handle) \
    get_active_queue(queue, queue_handle)   \
    get_tail(tail, queue)

#define set_active_tail(tail, queue_handle) \
    get_active_queue(queue, queue_handle)   \
    set_tail(tail, queue)

/**
 * from queue.pnk
 */

#define net_queue_empty_free(empty, queue_handle)   \
    get_free_tail(tail, queue_handle)               \
    get_free_head(head, queue_handle)               \
    var empty = (tail - head) == 0;                 \

#define net_queue_empty_active(empty, queue_handle) \
    get_active_tail(tail, queue_handle)             \
    get_active_head(head, queue_handle)             \
    var empty = (tail - head) == 0;                 \

#define net_queue_full_free(full, queue_handle)     \
    get_free_tail(tail, queue_handle)               \
    get_free_head(head, queue_handle)               \
    get_size(size, queue_handle)                    \
    var full = (tail + 1 - head) == size;           \

#define net_queue_full_active(full, queue_handle)   \
    get_active_tail(tail, queue_handle)             \
    get_active_head(head, queue_handle)             \
    get_size(size, queue_handle)                    \
    var full = (tail + 1 - head) == size;           \

fun net_enqueue_free(1 queue_handle, 2 buffer) {
    net_queue_full_free(full, queue_handle)
    if (full) {
        return -1;
    }

    get_size(size, queue_handle)
    get_free_tail(tail, queue_handle)
    pnk_modulo(idx, tail, size)

    get_free_queue(free, queue_handle)
    get_buffer_desc_addr(buff, idx, free)

    !stw buff, (buffer.0);
    !stw buff + WORD_SIZE, (buffer.1);

    THREAD_MEMORY_RELEASE()

    tail = tail + 1;
    set_free_tail(tail, queue_handle)
    return 0;
}

fun net_enqueue_active(1 queue_handle, 2 buffer) {
    net_queue_full_active(full, queue_handle)
    if (full) {
        return -1;
    }

    get_size(size, queue_handle)
    get_active_tail(tail, queue_handle)
    pnk_modulo(idx, tail, size)

    get_active_queue(active, queue_handle)
    get_buffer_desc_addr(buff, idx, active)

    !stw buff, (buffer.0);
    !stw buff + WORD_SIZE, (buffer.1);

    THREAD_MEMORY_RELEASE()

    tail = tail + 1;
    set_active_tail(tail, queue_handle)
    return 0;
}

fun net_dequeue_free(1 queue_handle, 1 buffer_addr) {
    net_queue_empty_free(empty, queue_handle)
    if (empty) {
        return -1;
    }

    get_size(size, queue_handle)
    get_free_head(head, queue_handle)
    pnk_modulo(idx, head, size)

    get_free_queue(free, queue_handle)
    get_buffer_desc_addr(buff, idx, free)

    var buf_v = 0;
    !ldw buf_v, buff;
    !stw buffer_addr, buf_v;
    !ldw buf_v, buff + WORD_SIZE;
    !stw buffer_addr + WORD_SIZE, buf_v;
    THREAD_MEMORY_RELEASE()

    head = head + 1;
    set_free_head(head, queue_handle)
    return 0;
}

fun net_dequeue_active(1 queue_handle, 1 buffer_addr) {
    net_queue_empty_active(empty, queue_handle)
    if (empty) {
        return -1;
    }

    get_size(size, queue_handle)
    get_active_head(head, queue_handle)
    pnk_modulo(idx, head, size)

    get_active_queue(active, queue_handle)
    get_buffer_desc_addr(buff, idx, active)

    var buf_v = 0;
    !ldw buf_v, buff;
    !stw buffer_addr, buf_v;
    !ldw buf_v, buff + WORD_SIZE;
    !stw buffer_addr + WORD_SIZE, buf_v;
    THREAD_MEMORY_RELEASE()

    head = head + 1;
    set_active_head(head, queue_handle)
    return 0;
}

/**
 * Indicate to producer of the free queue that consumer requires signalling.
 *
 * @param queue queue handle of free queue that requires signalling upon enqueuing.
 */
#define net_request_signal_free(queue_handle)   \
    get_free_queue(queue, queue_handle)         \
    clear_consumer_signalled(queue)             \
    THREAD_MEMORY_RELEASE()                     \

#define net_request_signal_active(queue_handle)     \
    get_active_queue(queue, queue_handle)           \
    clear_consumer_signalled(queue)                 \
    THREAD_MEMORY_RELEASE()                         \

#define net_cancel_signal_free(queue_handle)    \
    get_free_queue(queue, queue_handle)         \
    set_consumer_signalled(queue)               \
    THREAD_MEMORY_RELEASE()                     \

#define net_cancel_signal_active(queue_handle)      \
    get_active_queue(queue, queue_handle)           \
    set_consumer_signalled(queue)                   \
    THREAD_MEMORY_RELEASE()                         \

#define net_require_signal_free(signal, queue_handle)       \
    get_free_queue(queue, queue_handle)                     \
    get_consumer_signalled(signalled, queue)                \
    var signal = (!signalled);

#define net_require_signal_active(signal, queue_handle)     \
    get_active_queue(queue, queue_handle)                   \
    get_consumer_signalled(signalled, queue)                \
    var signal = (!signalled);

/**
 * from ethernet_helper.pnk
 */

#define NETIRQ_TXF      (1 << 27) /* Transmit Frame Interrupt        */
#define NETIRQ_RXF      (1 << 25) /* Receive Frame Interrupt         */
#define NETIRQ_EBERR    (1 << 22) /* Ethernet bus error              */

#define WRAP            (1 << 13)
#define RXD_EMPTY       (1 << 15)
#define TXD_READY       (1 << 15)
#define TXD_ADDCRC      (1 << 10)
#define TXD_LAST        (1 << 11)

#define ETH_FUNC_BASE                   @base + 8360
#define EIR_OFFSET                      4

#define RDAR_OFFSET                     16
#define TDAR_OFFSET                     20

#define get_eth_eir(eir, eth)           \
    var eir = 0;                        \
    !ld32 eir, (eth + EIR_OFFSET);      \

#define set_eth_eir(eir, eth)           \
    !st32 (eth + EIR_OFFSET), eir;      \

#define set_eth_rdar(rdar, eth)         \
    !st32 (eth + RDAR_OFFSET), rdar;    \

#define set_eth_tdar(tdar, eth)         \
    !st32 (eth + TDAR_OFFSET), tdar;    \

#define get_eth_regs(eth_regs)  \
    var addrs = @base;          \
    var eth_regs = lds 1 addrs; \

/* Pancake heap layout

              pancake heap 1024*9 bytes
             +--------------------------+
      [0..7] | eth regs addr            |
             +--------------------------+
     [9..31] | rx_queue {               |
             | free buffer ptr          +---->
             | active buffer ptr        +----> shared mem with virt_rx
             | queue size               |
             |}                         |
             +--------------------------+
    [32..55] | tx queue {               |
             | free buffer ptr          +---->
             | active buffer ptr        +----> shared mem with virt_tx
             | queue size               |
             |}                         |
             +--------------------------+
  [56..4175] | hw_ring tx {             |
             |  tail index              |
             |  head index              |
             |  buffers meta data       |
             |  buffer descriptors ptr  +----> shared mem with device
             | }                        |
             +--------------------------+
[4176..8295] | hw_ring rx {             |
             |  tail index              |
             |  head index              |
             |  buffers meta data       |
             |  buffer descriptors ptr  +----> shared mem with device
             | }                        |
             +--------------------------+
 [8296..9216]| dynamic heap             |
             |                          |
             |                          |
             |                          |
             |                          |
             |                          |
             +--------------------------+
 */

#define IRQ_CH 0
#define TX_CH  1
#define RX_CH  2

#define RX_COUNT 256
#define TX_COUNT 256
#define MAX_COUNT 256

#define MAX_PACKET_SIZE     1536

#define get_rx_queue(rx_queue)              \
    var rx_queue = @base + 3 * WORD_SIZE;   \

#define get_tx_queue(tx_queue)              \
    var tx_queue = @base + 6 * WORD_SIZE;   \

#define HW_RING_SIZE (3 * WORD_SIZE + MAX_COUNT * NET_BUFF_DESC_SIZE)

#define hw_ring_get_tail(tail, hw_ring)     \
    var tail = lds 1 hw_ring;               \

#define hw_ring_set_tail(tail, hw_ring)     \
    stw hw_ring, tail;                      \

#define hw_ring_get_head(head, hw_ring)     \
    var head = lds 1 hw_ring + WORD_SIZE;   \

#define hw_ring_set_head(head, hw_ring)     \
    stw hw_ring + WORD_SIZE, head;          \

#define hw_ring_get_descr_mdata(desc, index, hw_ring)       \
    var desc = hw_ring + 16 + index * NET_BUFF_DESC_SIZE;   \

#define hw_ring_get_descr(descr, hw_ring)                                   \
    var addr = hw_ring + (2 * WORD_SIZE) + MAX_COUNT * NET_BUFF_DESC_SIZE;  \
    var descr = lds 1 addr;                                                 \

#define hw_ring_full(result, hw_ring, ring_size)    \
    hw_ring_get_tail(tail, hw_ring)                 \
    hw_ring_get_head(head, hw_ring)                 \
    var value = tail - head;                        \
    pnk_modulo(mod, value, ring_size)               \
    var result = (mod == 0);                        \

#define hw_ring_empty(result, hw_ring, ring_size)   \
    hw_ring_get_tail(tail, hw_ring)                 \
    hw_ring_get_head(head, hw_ring)                 \
    var value = tail - head;                        \
    pnk_modulo(mod, value, ring_size)               \
    var result = (mod == 0);                        \

#define DESCRIPTOR_SIZE WORD_SIZE

#define get_hw_ring_rx(hw_ring_rx)          \
    var hw_ring_rx = @base + 9 * WORD_SIZE; \

#define get_hw_ring_tx(hw_ring_tx)                          \
    var hw_ring_tx = @base + 9 * WORD_SIZE + HW_RING_SIZE;  \

#define update_ring_slot(hw_ring, idx, phys, len, stat)     \
    hw_ring_get_descr(descr, hw_ring)                       \
    var dst_addr = descr + idx * DESCRIPTOR_SIZE;           \
    var descriptor = (stat << 16) | len;                    \
    !st32 dst_addr, descriptor;                             \
    !st32 dst_addr + 4, phys;                               \

fun main () {
    rx_provide();
    tx_provide();
    return 0;
}

/*
 * `rx_return()`: Transfer "active buffer" from device to `virt_rx`
 * 1. check if `hw_ring_rx` is not empty; if not then exit
 * 2. get a buffer from `head` slot of `hw_ring_rx`, make sure its status is non-empty
 * 3. increment `hw_ring_rx` head, enqueue the buffer to `rx_active`
 * 4. if `rx_active` requires signalling, cancel the signal and notify `virt_rx` via microkit
 */
fun rx_return() {
    var packets_transferred = false;
    get_hw_ring_rx(hw_ring_rx)
    get_rx_queue(rx_queue)

    while (true) {
        hw_ring_empty(empty, hw_ring_rx, RX_COUNT)
        if (empty) {
            break; // we have processed all packets the device has filled
        }
        // volatile struct descriptor *d = &(hw_ring_rx->descr[hw_ring_rx->hw_head]);
        hw_ring_get_head(hw_head, hw_ring_rx)
        hw_ring_get_descr(descr, hw_ring_rx)
        var dscr_addr = descr + hw_head * DESCRIPTOR_SIZE; // this is an shared mem address
        var descriptor = 0;
        !ld32 descriptor, dscr_addr;

        var stat = (descriptor >> 16) & MASK_16;
        if (stat & RXD_EMPTY) {
            break;
        }

        hw_ring_get_descr_mdata(buffer_addr, hw_head, hw_ring_rx)
        stw buffer_addr + WORD_SIZE, descriptor & MASK_16; // store len

        hw_ring_set_head(hw_head + 1, hw_ring_rx)

        var buffer = lds {1,1} buffer_addr;
        var 1 err = net_enqueue_active(rx_queue, buffer);
        assert(!err)
        packets_transferred = true;
    }

    net_require_signal_active(signal, rx_queue)
    if (packets_transferred && signal) {
        net_cancel_signal_active(rx_queue)
        microkit_notify(RX_CH)
    }
    return 0;
}

/*
 * `rx_provide()`: Transfer "free buffer" from `virt_rx` to device
 * 1. check if `hw_ring_rx` is not full, and `rx_queue` is not empty;  if not then exit
 * 2. dequeue a buffer from `rx_free`, update the buffer stat
 * 3. update the tail slot of `hw_ring_rx` to this buffer, increment `hw_ring_rx` tail
 * 4. set device `rdar` register
 * 5. set `rx_free` as require signalling if `hw_ring_rx` is not full
 * 6. recheck (1), process more if needed
*/
fun rx_provide() {
    var reprocess = true;
    get_hw_ring_rx(hw_ring_rx)
    get_rx_queue(rx_queue)
    get_eth_regs(eth)

    while (reprocess) {
        while (true) {
            hw_ring_full(full, hw_ring_rx, RX_COUNT)
            net_queue_empty_free(empty, rx_queue)
            if (full || empty) {
                break;
            }

            var buffer_addr = ETH_FUNC_BASE + 512;
            var 1 err = net_dequeue_free(rx_queue, buffer_addr);
            assert(!err)

            var stat = RXD_EMPTY; // uint16_t
            hw_ring_get_tail(hw_tail, hw_ring_rx)
            if ((hw_tail + 1) == RX_COUNT) {
                stat = (stat | WRAP) & MASK_16;
            }
            hw_ring_get_descr_mdata(hw_buff_addr, hw_tail, hw_ring_rx)
            var buffer = lds {1,1} buffer_addr;
            !stw hw_buff_addr, buffer.0;
            !stw hw_buff_addr + WORD_SIZE, buffer.1;

            var io_or_offset = buffer.0;
            pnk_modulo(mod_tail, hw_tail, RX_COUNT)
            update_ring_slot(hw_ring_rx, mod_tail, io_or_offset, 0, stat)

            hw_ring_set_tail(hw_tail + 1, hw_ring_rx)

            set_eth_rdar(RDAR_RDAR, eth)
        }

        // Only request a notification from virtualiser if HW ring not full
        hw_ring_full(full, hw_ring_rx, RX_COUNT)
        if (!full) {
            net_request_signal_free(rx_queue)
        } else {
            net_cancel_signal_free(rx_queue)
        }

        reprocess = false;

        net_queue_empty_free(empty, rx_queue)
        hw_ring_full(full, hw_ring_rx, RX_COUNT)
        if ((!empty) && (!full)) {
            net_cancel_signal_free(rx_queue)
            reprocess = true;
        }
    }
    return 0;
}

/*
 * `tx_provide()`: Transfer "active buffer" from `virt_tx` to device
 * 1. check if `hw_ring_tx` is not full, and `tx_active` is not empty; if not then exit
 * 2. dequeue a buffer from `tx_active`, update the buffer stat
 * 3. update the tail slot of `hw_ring_tx` to this buffer, increment `hw_ring_tx` tail
 * 4. set device `tdar` register
 * 5. set `tx_active` as require signalling
 * 6. recheck (1), process more if needed
 */
fun tx_provide() {
    var reprocess = true;
    get_hw_ring_tx(hw_ring_tx)
    get_tx_queue(tx_queue)
    get_eth_regs(eth)

    while (reprocess) {
        while (true) {
            hw_ring_full(full, hw_ring_tx, TX_COUNT)
            net_queue_empty_active(empty, tx_queue)
            if (full || empty) {
                break;
            }

            var buffer_addr = ETH_FUNC_BASE + 512;
            var 1 err = net_dequeue_active(tx_queue, buffer_addr);
            assert(!err)

            var stat = TXD_READY | TXD_ADDCRC | TXD_LAST; // uint16_t
            hw_ring_get_tail(hw_tail, hw_ring_tx)
            if ((hw_tail + 1) == TX_COUNT) {
                stat = (stat | WRAP) & MASK_16;
            }
            hw_ring_get_descr_mdata(hw_buff_addr, hw_tail, hw_ring_tx)
            var buffer = lds {1,1} buffer_addr;
            !stw hw_buff_addr, buffer.0;
            !stw hw_buff_addr + WORD_SIZE, buffer.1;

            var io_or_offset = buffer.0;
            pnk_modulo(mod_tail, hw_tail, TX_COUNT)
            update_ring_slot(hw_ring_tx, mod_tail, io_or_offset, buffer.1, stat)

            hw_ring_set_tail(hw_tail + 1, hw_ring_tx)

            set_eth_tdar(TDAR_TDAR, eth)
        }

        net_request_signal_active(tx_queue)
        reprocess = false;

        hw_ring_full(full, hw_ring_tx, TX_COUNT)
        net_queue_empty_active(empty, tx_queue)
        if ((!full) && (!empty)) {
            net_cancel_signal_active(tx_queue)
            reprocess = true;
        }
    }
    return 0;
}

/*
 * `tx_return()`: Transfer "free buffer" from device to `virt_tx`
 * 1. check  if `hw_ring_tx` is not empty; if not then exit
 * 2. get a buffer from `head` slot of `hw_ring_tx`, make sure it's been processed by the device; if not then exit
 * 3. increment `hw_ring_tx` head, reset the buffer length, enqueue the buffer to `tx_free`
 * 4. if `rx_free` requires signalling, cancel the signal and notify `virt_tx` via microkit
 */
fun tx_return() {
    var enqueued = false;
    get_hw_ring_tx(hw_ring_tx)
    get_tx_queue(tx_queue)

    while (true) {
        hw_ring_empty(empty, hw_ring_tx, TX_COUNT)
        if (empty) {
            break;
        }
        // Ensure that this buffer has been sent by the device
        hw_ring_get_head(hw_head, hw_ring_tx)
        hw_ring_get_descr(descr, hw_ring_tx)
        var dscr_addr = descr + hw_head * DESCRIPTOR_SIZE;
        var descriptor = 0;
        !ld32 descriptor, dscr_addr;

        var stat = (descriptor >> 16) & MASK_16;
        if (stat & TXD_READY) {
            break;
        }

        hw_ring_get_descr_mdata(buff, hw_head, hw_ring_tx)
        stw buff + WORD_SIZE, 0;

        hw_ring_set_head(hw_head + 1, hw_ring_tx)

        var buffer = lds {1,1} buff;
        var 1 err = net_enqueue_free(tx_queue, buffer);
        assert(!err)
        enqueued = true;
    }

    net_require_signal_free(signal, tx_queue)
    if (enqueued && signal) {
        net_cancel_signal_free(tx_queue)
        microkit_notify(TX_CH)
    }
    return 0;
}

fun handle_irq() {
    get_eth_regs(eth)
    get_eth_eir(eir, eth)

    var e = eir & IRQ_MASK;
    set_eth_eir(e, eth)

    while (e & IRQ_MASK) {
        if (e & NETIRQ_TXF) {
            tx_return();
        }
        if (e & NETIRQ_RXF) {
            rx_return();
            rx_provide();
        }
        if (e & NETIRQ_EBERR) {
            skip;
        }
        get_eth_eir(eir, eth)
        e = eir & IRQ_MASK;
        set_eth_eir(e, eth)
    }
    return 0;
}

export fun notified(1 channel) {
    if (channel == IRQ_CH) {
        handle_irq();
        microkit_irq_ack_delayed(channel)
        return 0;
    }

    if (channel == RX_CH) {
        rx_provide();
        return 0;
    }

    if (channel == TX_CH) {
        tx_provide();
        return 0;
    }

    @print_int(0,0,0,channel);
    return -1;
}
